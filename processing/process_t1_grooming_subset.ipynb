{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%run /media/turritopsis/katie/grooming/t1-grooming/grooming_functions.ipynb\n",
    "\n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "from scipy import signal, stats\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = 't1_grooming'\n",
    "prefix = '/media/turritopsis/katie/apviz/classifiers/2021_02_19'\n",
    "# prefix = '/media/turritopsis/katie/apviz/classifiers/2021_01_05'\n",
    "prefix_out = '/media/turritopsis/katie/grooming/summaries/v3-b2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from labels (angles, pose3d)\n",
    "data = pd.read_parquet(os.path.join(prefix, 'training_data.parquet'), engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.behavior == 't1_grooming']\n",
    "fly_decomp = data['flyid'].str.split(' ', n = 2, expand = True)\n",
    "data['Date'] = fly_decomp[0]\n",
    "data['Fly #'] = fly_decomp[2]\n",
    "data['flyid'] = data['Fly #'].astype(str) + ' ' + data['Date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = '/media/turritopsis/pierre/gdrive/Tuthill Lab Shared/Pierre/summaries/v3-b2/lines-t1_grooming'\n",
    "(root, dirs, files) = next(os.walk(p))\n",
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_flies = [file for file in files if 'Berlin-WT' in file and ('offball' not in file and 'headless' not in file)]\n",
    "hg_flies = [file for file in files if '39A11-gal4xUAS-10x-ChrimsonR' in file]\n",
    "ag_flies = [file for file in files if 'AntennalGrooming' in file]\n",
    "eg_flies = [file for file in files if 'EyeGrooming' in file]\n",
    "files = [*wt_flies, *hg_flies, *ag_flies, *eg_flies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_dict = {'evyn--Berlin-WT.pq':'berlin wt',\n",
    "             'sarah--rv1-Berlin-WT.pq':'berlin wt',\n",
    "             'sarah--rv3-Berlin-WT.pq':'berlin wt',\n",
    "             'sarah--rv4-Berlin-WT.pq':'berlin wt',\n",
    "             'sarah--rv2-39A11-gal4xUAS-10x-ChrimsonR.pq':'39A11 (head)',\n",
    "             'sarah--rv3-AntennalGrooming-w;25F11-AD;27H08-DBDxUAS-10x-ChrimsonR.pq':'25F11AD;27H08DBD (antennal)',\n",
    "             'sarah--rv3-AntennalGrooming-w;VT005525-AD(100C03);27H08-DBDxUAS-10x-ChrimsonR.pq':'VT005525AD;27H08DBD (antennal)',\n",
    "             'sarah--rv3-EyeGrooming-w;VT017251-LexA(3012796)xLexAop-Chrimson-tdTomato.pq':'VT017251 (eye)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evyn--Berlin-WT.pq\n",
      "sarah--rv1-Berlin-WT.pq\n",
      "sarah--rv3-Berlin-WT.pq\n",
      "sarah--rv4-Berlin-WT.pq\n",
      "sarah--rv2-39A11-gal4xUAS-10x-ChrimsonR.pq\n",
      "sarah--rv3-AntennalGrooming-w;25F11-AD;27H08-DBDxUAS-10x-ChrimsonR.pq\n",
      "sarah--rv3-AntennalGrooming-w;VT005525-AD(100C03);27H08-DBDxUAS-10x-ChrimsonR.pq\n",
      "sarah--rv3-EyeGrooming-w;VT017251-LexA(3012796)xLexAop-Chrimson-tdTomato.pq\n"
     ]
    }
   ],
   "source": [
    "#(root, dirs, files) = next(os.walk(prefix))\n",
    "# files = sorted(files)\n",
    "bout_num = 1\n",
    "thresh = 50\n",
    "session_datas = []\n",
    "\n",
    "for file in files:\n",
    "        \n",
    "    print(file)\n",
    "    path = os.path.join(p, file)\n",
    "    file_data = pd.read_parquet(path, engine='fastparquet')\n",
    "    cols_good = np.unique([v for v in file_data.columns\n",
    "              if not some_contains(v, ['_range', '_score', '_error', '_ncams',\n",
    "                                       '_prob', '_class', '_bout_number'])])\n",
    "    cols_good = np.append(cols_good, ['behavior_bout', 'line'])\n",
    "    if len(file_data) == 0:\n",
    "        continue\n",
    "        \n",
    "    sessions = np.unique(file_data.Date)\n",
    "    for session in sessions:\n",
    "        \n",
    "        session_data = file_data[file_data['Date'] == session]\n",
    "        dsub = session_data[session_data[behavior + '_class']]\n",
    "        d = dsub[~dsub['t1_grooming_bout_number'].isna()]\n",
    "        bout_numbers = np.unique(d['t1_grooming_bout_number'])\n",
    "\n",
    "        for j in range(len(bout_numbers)): \n",
    "            bout = dsub[dsub['t1_grooming_bout_number'] == bout_numbers[j]]\n",
    "            bout['behavior_bout'] = bout_num\n",
    "            bout['line'] = line_dict[file]\n",
    "            if len(bout) >= thresh:\n",
    "                session_datas.append(bout[cols_good])\n",
    "                bout_num += 1\n",
    "        \n",
    "df = pd.concat(session_datas)\n",
    "df['flyid'] = df['Fly #'].astype(str) + ' ' + df['Date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10_0 10.22.20' '1_0 10.22.20' '1_0 11.5.20' '1_0 11.6.20' '1_0 12.10.20'\n",
      " '1_0 12.16.20' '1_0 5.22.19' '1_0 5.24.19' '1_0 5.27.19' '1_0 6.10.20'\n",
      " '1_0 6.11.20' '1_0 6.15.20' '1_0 6.3.20' '1_0 6.4.20' '1_0 6.5.20'\n",
      " '1_0 7.10.19' '1_1 10.19.20' '1_1 10.6.20' '1_1 11.5.20' '1_1 11.6.20'\n",
      " '1_2 8.31.20' '1_2 9.1.20' '2_0 10.22.20' '2_0 11.5.20' '2_0 11.6.20'\n",
      " '2_0 12.10.20' '2_0 5.27.19' '2_0 6.10.20' '2_0 6.11.20' '2_0 6.15.20'\n",
      " '2_0 6.3.20' '2_0 6.4.20' '2_0 6.5.20' '2_0 8.31.20' '2_0 9.1.20'\n",
      " '2_1 11.5.20' '2_1 11.6.20' '2_1 12.16.20' '3_0 10.21.20' '3_0 10.22.20'\n",
      " '3_0 11.5.20' '3_0 5.22.19' '3_0 5.27.19' '3_0 6.10.20' '3_0 6.11.20'\n",
      " '3_0 6.3.20' '3_0 6.4.20' '3_0 6.5.20' '3_0 8.28.20' '3_0 9.1.20'\n",
      " '3_1 11.5.20' '3_1 8.28.20' '3_2 8.28.20' '3_3 8.28.20' '4_0 10.21.20'\n",
      " '4_0 10.22.20' '4_0 11.21.19' '4_0 12.11.20' '4_0 12.15.20' '4_0 5.22.19'\n",
      " '4_0 5.27.19' '4_0 6.10.20' '4_0 6.11.20' '4_0 6.15.20' '4_0 6.4.20'\n",
      " '4_0 6.5.20' '4_0 9.1.20' '5_0 10.21.20' '5_0 10.22.20' '5_0 5.22.19'\n",
      " '5_0 5.27.19' '5_0 6.10.20' '5_0 6.19.19' '5_0 6.4.20' '5_0 9.1.20'\n",
      " '6_0 10.21.20' '6_0 10.22.20' '6_0 6.4.20' '6_0 9.1.20' '7_0 10.21.20'\n",
      " '7_0 10.22.20' '7_0 6.4.20' '7_0 9.1.20' '8_0 10.22.20' '8_0 6.4.20'\n",
      " '9_0 10.22.20']\n",
      "['10_0 10.22.20' '1_0 10.22.20' '1_0 11.5.20' '1_0 11.6.20' '1_0 12.10.20'\n",
      " '1_0 12.16.20' '1_0 5.22.19' '1_0 5.24.19' '1_0 5.27.19' '1_0 6.10.20'\n",
      " '1_0 6.11.20' '1_0 6.15.20' '1_0 6.3.20' '1_0 6.4.20' '1_0 6.5.20'\n",
      " '1_0 7.10.19' '1_1 10.19.20' '1_1 10.6.20' '1_1 11.5.20' '1_1 11.6.20'\n",
      " '1_2 8.31.20' '1_2 9.1.20' '2_0 10.22.20' '2_0 11.5.20' '2_0 11.6.20'\n",
      " '2_0 12.10.20' '2_0 5.27.19' '2_0 6.10.20' '2_0 6.11.20' '2_0 6.15.20'\n",
      " '2_0 6.3.20' '2_0 6.4.20' '2_0 6.5.20' '2_0 8.31.20' '2_0 9.1.20'\n",
      " '2_1 11.5.20' '2_1 11.6.20' '2_1 12.16.20' '3_0 10.21.20' '3_0 10.22.20'\n",
      " '3_0 11.5.20' '3_0 5.22.19' '3_0 5.27.19' '3_0 6.10.20' '3_0 6.11.20'\n",
      " '3_0 6.3.20' '3_0 6.4.20' '3_0 6.5.20' '3_0 8.28.20' '3_0 9.1.20'\n",
      " '3_1 11.5.20' '3_1 8.28.20' '3_2 8.28.20' '3_3 8.28.20' '4_0 10.21.20'\n",
      " '4_0 10.22.20' '4_0 11.21.19' '4_0 12.11.20' '4_0 12.15.20' '4_0 5.22.19'\n",
      " '4_0 5.27.19' '4_0 6.10.20' '4_0 6.11.20' '4_0 6.15.20' '4_0 6.4.20'\n",
      " '4_0 6.5.20' '4_0 9.1.20' '5_0 10.21.20' '5_0 10.22.20' '5_0 5.22.19'\n",
      " '5_0 5.27.19' '5_0 6.10.20' '5_0 6.19.19' '5_0 6.4.20' '5_0 9.1.20'\n",
      " '6_0 10.21.20' '6_0 10.22.20' '6_0 6.4.20' '6_0 9.1.20' '7_0 10.21.20'\n",
      " '7_0 10.22.20' '7_0 6.4.20' '7_0 9.1.20' '8_0 10.22.20' '8_0 6.4.20'\n",
      " '9_0 10.22.20']\n"
     ]
    }
   ],
   "source": [
    "fly_ids = np.unique(data['flyid'])\n",
    "print(fly_ids)\n",
    "print(np.unique(data['flyid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10.21.20', '10.22.20', '11.5.20', '11.6.20', '12.10.20',\n",
       "       '12.11.20', '12.15.20', '12.16.20', '5.22.19', '5.24.19',\n",
       "       '5.27.19', '6.10.20', '6.11.20', '6.15.20', '6.3.20', '6.4.20',\n",
       "       '6.5.20', '8.28.20', '8.31.20', '9.1.20'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata = df[df['flyid'].isin(fly_ids)]\n",
    "np.unique(ndata.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust data\n",
    "def adjust_rot_angles(angles, angle_names):\n",
    "    conds = ['2', '3', 'L1A', 'L1B', 'L1C', 'R1A', 'R1B', 'R1C']\n",
    "    offsets = np.array([-50, -20, 20, -70, 10, 20, 70, -30])\n",
    "    for j in range(len(conds)):\n",
    "        rot_angs = [r for r in angle_names if '_rot' in r and conds[j] in r]\n",
    "        for ang in rot_angs:\n",
    "            r = np.array(angles[ang])\n",
    "            r[r > offsets[j]] = r[r > offsets[j]] - 360\n",
    "            angles[ang] = r\n",
    "        \n",
    "    abduct_angs = [r for r in angle_names if '_abduct' in r or 'A_flex' in r]\n",
    "    for ang in abduct_angs:\n",
    "        r = np.array(angles[ang])\n",
    "        r[r > 50] = r[r > 50] - 360\n",
    "        angles[ang] = r\n",
    "        \n",
    "    return angles\n",
    "\n",
    "angle_vars = np.unique([v for v in data.columns\n",
    "              if some_contains(v, ['_BC', '_flex', '_rot', '_abduct'])\n",
    "              and not some_contains(v, ['_d1', '_d2', '_freq', '_range'])])\n",
    "ndata = correct_angles(ndata, angle_vars)\n",
    "ndata = adjust_rot_angles(ndata, angle_vars)\n",
    "ndata = normalize_data(ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save if all labels are manual \n",
    "path_out = os.path.join(prefix_out, 't1_grooming_subset_curated.parquet')\n",
    "ndata.to_parquet(path_out, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              berlin_wt\n",
       "1              berlin_wt\n",
       "2              berlin_wt\n",
       "3              berlin_wt\n",
       "4              berlin_wt\n",
       "               ...      \n",
       "140018    VT017251 (eye)\n",
       "140019    VT017251 (eye)\n",
       "140020    VT017251 (eye)\n",
       "140021    VT017251 (eye)\n",
       "140022    VT017251 (eye)\n",
       "Name: line, Length: 353739, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndata.line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove head_grooming from t1_grooming data (dont run if labels are all manual)\n",
    "features = [v for v in data.columns\n",
    "              if some_contains(v, ['_flex', '_rot', '_x', '_y', '_z'])\n",
    "              and not some_contains(v, ['_d1', '_d2', '_freq', '_range'])\n",
    "              and v[:2] == 'L1']\n",
    "feature_names= ['L1B_rot_avg_range', 'L1A_flex_avg_range', 'L1E_z_avg_range', 'L1D_z', 'L1E_z']\n",
    "flip = [False, False, False, True, True]\n",
    "data = compute_grooming_scores(data, features, feature_names, flip = flip, dist=20, norm=False)\n",
    "df0 = data[data.grooming_score < 8.25]\n",
    "df = df0[df0.grooming_score > 1.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save with the grooming score before removing bouts with certain scores?\n",
    "cols_good = np.unique([v for v in ndata.columns\n",
    "              if not some_contains(v, ['_range', '_error', '_ncams', '_prob', '_class', '_bout_number'])])\n",
    "\n",
    "# out = os.path.join(prefix_out, 'lines-' + behavior + '_onball_processed_all_gs.parquet')\n",
    "out = os.path.join(prefix_out, 'subset_t1_grooming_all_gs.parquet')\n",
    "ndata = ndata[cols_good]\n",
    "ndata.to_parquet(out, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_good = np.unique([v for v in df.columns\n",
    "              if not some_contains(v, ['_range', '_error', '_ncams', '_prob', '_class', '_bout_number'])])\n",
    "df = df[cols_good]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_out = os.path.join(prefix_out, 'lines-' + behavior + '_onball_processed.parquet')\n",
    "path_out = os.path.join(prefix_out, 't1_grooming_subset_curated.parquet')\n",
    "df.to_parquet(path_out, compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324631\n",
      "964\n",
      "359873\n",
      "1120\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(np.unique(df.behavior_bout)))\n",
    "print(len(data))\n",
    "print(len(np.unique(data.behavior_bout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
